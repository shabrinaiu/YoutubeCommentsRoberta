{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "KIw22WL7t6Lc",
    "outputId": "9fc813df-fab1-42a3-d891-f9c38148b6bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     0\n",
      "0                                                 text\n",
      "1    Been a long ass time since I uploaded on this ...\n",
      "2    There is a whole science of passing interviews...\n",
      "3    I have solved 65 Leetcode exercises + about 50...\n",
      "4    You know Pepe the Frog has been co-opted by ra...\n",
      "..                                                 ...\n",
      "546  I just finished 100 problem as per your strate...\n",
      "547  Do you mean it's better to solve Neetcode 150 ...\n",
      "548                                              Third\n",
      "549                                   Love the content\n",
      "550                                              First\n",
      "\n",
      "[551 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# import csv\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('cleaned_comments.csv', header=None)\n",
    "\n",
    "print(df)\n",
    "df_saved = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LyiMcKfMT5ER",
    "outputId": "ec4b0b50-d08f-4958-d6d9-b0ffd47dbf3b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PPTI Java\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\PPTI\n",
      "[nltk_data]     Java\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\PPTI\n",
      "[nltk_data]     Java\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downlaoad NLTK\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "8Ds1mMFiWIpe",
    "outputId": "771288d4-31c8-4bc7-8699-7cd1265eda8a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>been a long ass time since i uploaded on this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>there is a whole science of passing interviews...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i have solved 65 leetcode exercises + about 50...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you know pepe the frog has been co-opted by ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>i just finished 100 problem as per your strate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>do you mean it's better to solve neetcode 150 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>third</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>love the content</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>first</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>551 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     0\n",
       "0                                                 text\n",
       "1    been a long ass time since i uploaded on this ...\n",
       "2    there is a whole science of passing interviews...\n",
       "3    i have solved 65 leetcode exercises + about 50...\n",
       "4    you know pepe the frog has been co-opted by ra...\n",
       "..                                                 ...\n",
       "546  i just finished 100 problem as per your strate...\n",
       "547  do you mean it's better to solve neetcode 150 ...\n",
       "548                                              third\n",
       "549                                   love the content\n",
       "550                                              first\n",
       "\n",
       "[551 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Case Folding\n",
    "df = df.applymap(lambda s: s.lower() if type(s) == str else s)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "terd0rFnXTsC",
    "outputId": "68abcb54-1080-41ed-f124-076b136e11c4"
   },
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "import re\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Remove Number\n",
    "df = df.applymap(lambda s: re.sub(r\"\\d+\", \"\", s) if type(s) == str else s)\n",
    "\n",
    "# Remove punctuation\n",
    "# translator = str.maketrans(\"\", \"\", string.punctuation)\n",
    "# df = df.applymap(lambda s: s.translate(translator) if type(s) == str else s)\n",
    "\n",
    "# Trim whitespace\n",
    "df = df.applymap(lambda s: s.strip() if type(s) == str else s)\n",
    "\n",
    "# Change whitespace in between text into a single whitespace\n",
    "df = df.applymap(lambda s: re.sub('\\s+',' ', s) if type(s) == str else s)\n",
    "\n",
    "# Tokenize\n",
    "df_tokens = df.applymap(lambda s: word_tokenize(s) if type(s) == str else s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "vd4_8cSfZuwQ",
    "outputId": "44007642-c7d3-43c1-cc7a-6b68417775bc"
   },
   "outputs": [],
   "source": [
    "# Stop Words Removal\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "\n",
    "en_list_stopwords = set(stopwords.words('english'))\n",
    "# id_list_stopwords = set(stopwords.words('indonesian'))\n",
    "\n",
    "df_tokens = df_tokens.applymap(lambda s: [word for word in s if not word in en_list_stopwords] if type(s) == list else s)\n",
    "\n",
    "df_tokens[0] = df_tokens[0].replace('', np.nan).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[text]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[long, ass, time, sinc, upload, channel, ,, kn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[whole, scienc, pass, interview, ., job, ., pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[solv, leetcod, exercis, +, hackerrank, (, ugl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[know, pepe, frog, co-opt, racist, ,, ’, ?, ’,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>[finish, problem, per, strategi, person_surf]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>[mean, 's, better, solv, neetcod, rather, go, ?]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>[third]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>[love, content]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>[first]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>551 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     0\n",
       "0                                               [text]\n",
       "1    [long, ass, time, sinc, upload, channel, ,, kn...\n",
       "2    [whole, scienc, pass, interview, ., job, ., pa...\n",
       "3    [solv, leetcod, exercis, +, hackerrank, (, ugl...\n",
       "4    [know, pepe, frog, co-opt, racist, ,, ’, ?, ’,...\n",
       "..                                                 ...\n",
       "546      [finish, problem, per, strategi, person_surf]\n",
       "547   [mean, 's, better, solv, neetcod, rather, go, ?]\n",
       "548                                            [third]\n",
       "549                                    [love, content]\n",
       "550                                            [first]\n",
       "\n",
       "[551 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "df_output = df_tokens.applymap(lambda s: [stemmer.stem(word) for word in s] if type(s) == list else s)\n",
    "df_output\n",
    "\n",
    "# Save the DataFrame as a CSV file\n",
    "# df_output.to_csv('comment_file_video1_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(1, 552)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = range(1, len(df) + 1)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to C:\\Users\\PPTI\n",
      "[nltk_data]     Java\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "new_column_values = []\n",
    "df_output[:3]\n",
    "for index, row in df_output.iterrows():\n",
    "    # Example: Let's create a new column 'SquaredAge' that contains the square of the 'Age' column\n",
    "    # squared_age = row['Age'] ** 2\n",
    "    # print(df_output[0][index])\n",
    "    try:\n",
    "        sentence = ' '.join(df_output[0][index])\n",
    "        sentiment_scores = sia.polarity_scores(sentence)\n",
    "        # print(' '.join(df_output[0][index]))\n",
    "        df_output[0][index] = sentence\n",
    "        value = 2\n",
    "        if sentiment_scores['neg'] > sentiment_scores['pos'] and sentiment_scores['neg'] > sentiment_scores['neu']:\n",
    "            value = 0\n",
    "        elif sentiment_scores['neu'] > sentiment_scores['pos']:\n",
    "            value = 1\n",
    "    except Exception as e:\n",
    "        value = -1\n",
    "    \n",
    "    new_column_values.append(value)\n",
    "# new_column_values.shape()\n",
    "df_output['label'] = new_column_values\n",
    "df_output\n",
    "df_output['text'] = df_output[0]\n",
    "df_output = df_output.drop(0, axis=1)\n",
    "df_output.replace('', np.nan, inplace=True)\n",
    "df_output = df_output.dropna(subset=['text'])\n",
    "df_output.to_csv('new_comment_labeled_raw.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "ZvitxtPjacU3",
    "outputId": "78d7092c-cace-4a36-fb4f-a1986d901569"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
